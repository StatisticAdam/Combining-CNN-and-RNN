# Combining-CNN-and-RNN
用一维卷积处理序列问题，提出优化方法：结合CNN和RNN来处理长序列
引言：CNN在计算机视觉问题上表现出色，原因在于它能够进行卷积运算，从局部输入图块中提取特征，并能将表示模块化，同时可以高效地利用数据，同样也让它对序列处理特别有效，时间可以被看做一个空间维度，就像二维图像的高或宽。对于某些序列处理问题，这种一维卷积的效果甚至可以媲美RNN，而且计算代价通常要小很多。近年，一维卷积网络通常与空洞卷积核一起使用，在音频生成和机器翻译领域取得了巨大的成功。
一：理解序列数据的一维卷积
使用一维卷积，从序列中提取局部一维序列段，这种一维卷积可以识别序列中的局部模式。对每个序列段执行相同的输入变换，所以在句子中某个位置学到的模式稍后可以在其他位置被识别，这使得一维卷积神经网络具有平移不变性。如图：
![a0c223355006c5dab2750eb36d2364e](https://user-images.githubusercontent.com/118498273/233898503-9aefa0cf-fc8e-4fc4-8fba-cc10060ee177.jpg)
二：序列数据的一维池化
一维也可以做池化运算：从输入中提取一维序列段，然后输出其最大值或平均值。用于降低一维输入的长度。
三：一维卷积代码
可以看附件
时间原因，epochs只取了4。可以将以上结果与循环网络进行比较，发现验证精度相似，更让我们确信，在单词级的情感分类任务上，一维卷积可以代替RNN，而且速度快，计算代价低。
四、结合CNN和RNN来处理长序列
一维卷积神经网络分别处理每个输入序列段，所以它对时间步的顺序不敏感，与RNN不同。为了识别长期的模式，可以将许多卷积层和池化层堆叠在一起，这样上面的层能够观察到原始输入中更长的序列段，但这仍不是一种引入顺序敏感性的好方法。可以选择结合卷积神经网络的速度和轻量与RNN的顺序敏感性，可以在RNN前使用一维卷积作为预处理步骤。对于那些非常长，以至于RNN无法处理的序列，这个方法嘎嘎好用！卷积网络可以将长的输入序列转换为高级特征组成的更短序列（下采样）。然后提取的特征组成的这些序列成为网络中RNN的输入。我们将这个方法运用到温度预测数据集，该数据集在作者上一篇博客介绍过了，这里就不进行介绍。这种方法允许操作更长的序列，所以我们可以查看更早的数据（通过增大数据生成器的lookback参数）或查看分辨率更高的时间序列（通过减小生成器的step参数）。这里将step减半，得到时间序列的长度变为之前的两倍，温度数据的采样频率变为每30min一个数据点。
从验证随时来看，这种架构的效果不如只用正则化GRU，但速度快。他查看了两倍的数据量，在本例可能用处并不能完全发挥出来，但对其他某些数据可能效果非常好！
欢迎读者批评指正，有任何问题可以评论发私信等！感谢读者，恳求点赞+关注，谢谢啦！
